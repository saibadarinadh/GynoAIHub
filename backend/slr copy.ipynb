{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Badari\\AppData\\Local\\Temp\\ipykernel_38904\\2901762267.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
      "C:\\Users\\Badari\\AppData\\Local\\Temp\\ipykernel_38904\\2901762267.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
      "C:\\Users\\Badari\\AppData\\Local\\Temp\\ipykernel_38904\\2901762267.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
      "C:\\Users\\Badari\\AppData\\Local\\Temp\\ipykernel_38904\\2901762267.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
      "C:\\Users\\Badari\\AppData\\Local\\Temp\\ipykernel_38904\\2901762267.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
      "C:\\Users\\Badari\\AppData\\Local\\Temp\\ipykernel_38904\\2901762267.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
      "C:\\Users\\Badari\\AppData\\Local\\Temp\\ipykernel_38904\\2901762267.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Metrics:\n",
      "Disorder:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "Treatment Recommendation:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "Precautions:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "Food Intake Recommendation:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "Foods to Avoid:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "Duration of Symptoms:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "Lifestyle Recommendations:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 1.0000\n"
     ]
    },
    {
     "ename": "FileDataError",
     "evalue": "'.' is no file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileDataError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38904\\2901762267.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;31m# User input for PDF file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[0mpdf_file_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please enter the path to the PDF file: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;31m# Extract symptoms from the PDF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m \u001b[0mextracted_symptoms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;31m# Predict outputs based on the extracted symptoms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[0mpredicted_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextracted_symptoms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38904\\2901762267.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mfitz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpdf_document\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpdf_document\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pymupdf\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[0;32m   3066\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count_pdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count_fz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3070\u001b[1;33m             \u001b[0mJM_mupdf_show_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJM_mupdf_show_errors_old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileDataError\u001b[0m: '.' is no file"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pickle\n",
    "import fitz  # PyMuPDF for PDF text extraction\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('gynecological_conditions.csv', on_bad_lines='skip')\n",
    "\n",
    "\n",
    "# Define input features and targets\n",
    "X = data['Symptoms']  # Input features (Symptoms)\n",
    "\n",
    "# Targets for prediction\n",
    "targets = [\n",
    "    'Disorder',\n",
    "    'Treatment Recommendation',\n",
    "    'Precautions',\n",
    "    'Food Intake Recommendation',\n",
    "    'Foods to Avoid',\n",
    "    'Duration of Symptoms',\n",
    "    'Lifestyle Recommendations'\n",
    "]\n",
    "\n",
    "# Encode the target columns\n",
    "target_data = data[targets]\n",
    "le_targets = {}\n",
    "for target in targets:\n",
    "    le_targets[target] = LabelEncoder()\n",
    "    target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "y_train = target_data.loc[X_train.index]\n",
    "y_test = target_data.loc[X_test.index]\n",
    "\n",
    "# Vectorize the symptoms data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Ensemble model setup\n",
    "logreg = LogisticRegression()\n",
    "svm = SVC(probability=True)  # Set probability=True for soft voting\n",
    "rf = RandomForestClassifier()\n",
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('svm', svm),\n",
    "    ('rf', rf)\n",
    "], voting='soft')\n",
    "\n",
    "# Dictionary to store final ensemble models for each target\n",
    "models = {}\n",
    "ensemble_metrics = {}\n",
    "\n",
    "# Train and evaluate ensemble models with metrics\n",
    "for target in targets:\n",
    "    voting_model.fit(X_train_vectorized, y_train[target])  # Train ensemble model for each target\n",
    "    y_pred = voting_model.predict(X_test_vectorized)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test[target], y_pred)\n",
    "    precision = precision_score(y_test[target], y_pred, average='weighted', zero_division=1)\n",
    "    recall = recall_score(y_test[target], y_pred, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(y_test[target], y_pred, average='weighted', zero_division=1)\n",
    "\n",
    "    # Store metrics\n",
    "    ensemble_metrics[target] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    }\n",
    "    models[target] = voting_model  # Store trained ensemble model\n",
    "\n",
    "# Print ensemble model metrics\n",
    "print(\"Ensemble Model Metrics:\")\n",
    "for target, metrics in ensemble_metrics.items():\n",
    "    print(f\"{target}:\")\n",
    "    print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"  F1 Score: {metrics['f1_score']:.4f}\")\n",
    "\n",
    "# Save the trained ensemble models and vectorizer to files\n",
    "with open('naive_bayes_treatment_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(models, model_file)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)\n",
    "\n",
    "# Prediction function using the ensemble model\n",
    "def predict_outputs(symptoms):\n",
    "    # Vectorize the input symptoms\n",
    "    input_vectorized = vectorizer.transform([symptoms])\n",
    "    predictions = {}\n",
    "    for target in targets:\n",
    "        predicted_encoded = models[target].predict(input_vectorized)\n",
    "        predictions[target] = le_targets[target].inverse_transform(predicted_encoded)[0]\n",
    "    return predictions\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as pdf_document:\n",
    "        for page in pdf_document:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# User input for PDF file\n",
    "pdf_file_path = input(\"Please enter the path to the PDF file: \")\n",
    "\n",
    "# Extract symptoms from the PDF\n",
    "extracted_symptoms = extract_text_from_pdf(pdf_file_path)\n",
    "\n",
    "# Predict outputs based on the extracted symptoms\n",
    "predicted_outputs = predict_outputs(extracted_symptoms)\n",
    "\n",
    "# Print the predicted outputs in the specified format\n",
    "print(f\"Based on extracted symptoms from '{pdf_file_path}':\")\n",
    "print(f\"Disorder: {predicted_outputs['Disorder']}\")\n",
    "print(f\"Treatment Recommendation: {predicted_outputs['Treatment Recommendation']}\")\n",
    "print(f\"Precautions: {predicted_outputs['Precautions']}\")\n",
    "print(f\"Recommended Food Intake: {predicted_outputs['Food Intake Recommendation']}\")\n",
    "print(f\"Foods to Avoid: {predicted_outputs['Foods to Avoid']}\")\n",
    "print(f\"Duration of Symptoms: {predicted_outputs['Duration of Symptoms']}\")\n",
    "print(f\"Lifestyle Recommendations: {predicted_outputs['Lifestyle Recommendations']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
