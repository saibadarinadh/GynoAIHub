{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7hTGutlrCF4",
        "outputId": "8b789b50-4d62-41bf-d097-e311a4842584"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import pickle\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/gynecological_conditions.csv')\n",
        "\n",
        "# View dataset columns to understand the structure\n",
        "print(data.columns)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvLLdyCtkWUK",
        "outputId": "bfd1aac0-6e0f-4ced-f7b7-498e82b31a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Disorder', 'Symptoms', 'Treatment Recommendation',\n",
            "       'Food Intake Recommendation', 'Precautions', 'Foods to Avoid',\n",
            "       'Duration of Symptoms', 'Lifestyle Recommendations'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMVTwyQwqBDn",
        "outputId": "6d444f8d-53b4-4b50-eae5-12a392542c88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.12-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading PyMuPDF-1.24.12-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#uploading pdf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pickle\n",
        "import fitz  # PyMuPDF for PDF text extraction\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/gynecological_conditions.csv')\n",
        "\n",
        "# View dataset columns to understand the structure\n",
        "print(data.columns)\n",
        "\n",
        "# Define input features and targets\n",
        "X = data['Symptoms']  # Input features (Symptoms)\n",
        "\n",
        "# Targets for prediction\n",
        "targets = ['Disorder', 'Treatment Recommendation', 'Precautions', 'Food Intake Recommendation']\n",
        "target_data = data[targets]\n",
        "\n",
        "# Encoding targets\n",
        "le_targets = {}\n",
        "for target in targets:\n",
        "    le_targets[target] = LabelEncoder()\n",
        "    target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
        "\n",
        "# Split the dataset into training and testing sets for the features\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
        "\n",
        "# Get the corresponding target values for the training and testing sets\n",
        "y_train = target_data.loc[X_train.index]\n",
        "y_test = target_data.loc[X_test.index]\n",
        "\n",
        "# Vectorize the symptoms data\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Train separate Naive Bayes models for each target\n",
        "models = {}\n",
        "for target in targets:\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train_vectorized, y_train[target])  # Using y_train[target] to match the length of X_train_vectorized\n",
        "    models[target] = model\n",
        "\n",
        "# Save the trained models and vectorizer to files\n",
        "with open('naive_bayes_treatment_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(models, model_file)\n",
        "\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
        "    pickle.dump(vectorizer, vectorizer_file)\n",
        "\n",
        "# Function to predict disorder, treatment, precautions, and food intake based on symptoms input\n",
        "def predict_outputs(symptoms):\n",
        "    # Vectorize the input symptoms\n",
        "    input_vectorized = vectorizer.transform([symptoms])\n",
        "\n",
        "    predictions = {}\n",
        "    for target in targets:\n",
        "        predicted_encoded = models[target].predict(input_vectorized)\n",
        "        predictions[target] = le_targets[target].inverse_transform(predicted_encoded)[0]\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as pdf_document:\n",
        "        for page in pdf_document:\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# User input for PDF file\n",
        "pdf_file_path = input(\"Please enter the path to the PDF file: \")\n",
        "\n",
        "# Extract symptoms from the PDF\n",
        "extracted_symptoms = extract_text_from_pdf(pdf_file_path)\n",
        "\n",
        "# Predict outputs based on the extracted symptoms\n",
        "predicted_outputs = predict_outputs(extracted_symptoms)\n",
        "\n",
        "# Print the predicted outputs along with the disorder\n",
        "print(f\"Based on extracted symptoms from '{pdf_file_path}':\")\n",
        "print(f\"Disorder: {predicted_outputs['Disorder']}\")\n",
        "print(f\"Treatment Recommendation: {predicted_outputs['Treatment Recommendation']}\")\n",
        "print(f\"Precautions: {predicted_outputs['Precautions']}\")\n",
        "print(f\"Recommended Food Intake: {predicted_outputs['Food Intake Recommendation']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fOKz8PIA7dV",
        "outputId": "fac13d78-9401-43ed-c793-83e338ffca6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-603d82418174>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-4-603d82418174>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-4-603d82418174>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-4-603d82418174>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Disorder', 'Symptoms', 'Treatment Recommendation',\n",
            "       'Food Intake Recommendation', 'Precautions', 'Foods to Avoid',\n",
            "       'Duration of Symptoms', 'Lifestyle Recommendations'],\n",
            "      dtype='object')\n",
            "Please enter the path to the PDF file: /content/PCOS_Medical_Report.pdf\n",
            "Based on extracted symptoms from '/content/PCOS_Medical_Report.pdf':\n",
            "Disorder: PCOS\n",
            "Treatment Recommendation: Medications, surgery\n",
            "Precautions: Maintain healthy weight, monitor cycles\n",
            "Recommended Food Intake: Iron-rich foods\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwxqQRRfFyYO",
        "outputId": "676b1abd-535a-4747-9976-87bcd5775621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (10.4.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NVT9AKAGjkd",
        "outputId": "2fcb2df6-ad13-4401-adec-f8a0ae5dc182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (10.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.24.0)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.6)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2024.6.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (912 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, easyocr\n",
            "Successfully installed easyocr-1.7.2 ninja-1.11.1.1 pyclipper-1.3.0.post6 python-bidi-0.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#uploading image\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pickle\n",
        "import easyocr\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/gynecological_conditions.csv')\n",
        "\n",
        "# View dataset columns to understand the structure\n",
        "print(data.columns)\n",
        "\n",
        "# Define input features and targets\n",
        "X = data['Symptoms']  # Input features (Symptoms)\n",
        "\n",
        "# Targets for prediction\n",
        "targets = ['Disorder', 'Treatment Recommendation', 'Precautions', 'Food Intake Recommendation']\n",
        "target_data = data[targets]\n",
        "\n",
        "# Encoding targets\n",
        "le_targets = {}\n",
        "for target in targets:\n",
        "    le_targets[target] = LabelEncoder()\n",
        "    target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
        "\n",
        "# Split the dataset into training and testing sets for the features\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
        "\n",
        "# Get the corresponding target values for the training and testing sets\n",
        "y_train = target_data.loc[X_train.index]\n",
        "y_test = target_data.loc[X_test.index]\n",
        "\n",
        "# Vectorize the symptoms data\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Train separate Naive Bayes models for each target\n",
        "models = {}\n",
        "for target in targets:\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train_vectorized, y_train[target])  # Using y_train[target] to match the length of X_train_vectorized\n",
        "    models[target] = model\n",
        "\n",
        "# Save the trained models and vectorizer to files\n",
        "with open('naive_bayes_treatment_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(models, model_file)\n",
        "\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
        "    pickle.dump(vectorizer, vectorizer_file)\n",
        "\n",
        "# Function to predict disorder, treatment, precautions, and food intake based on symptoms input\n",
        "def predict_outputs(symptoms):\n",
        "    # Vectorize the input symptoms\n",
        "    input_vectorized = vectorizer.transform([symptoms])\n",
        "\n",
        "    predictions = {}\n",
        "    for target in targets:\n",
        "        predicted_encoded = models[target].predict(input_vectorized)\n",
        "        predictions[target] = le_targets[target].inverse_transform(predicted_encoded)[0]\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Function to extract text from an image using EasyOCR\n",
        "def extract_text_from_image(image_path):\n",
        "    reader = easyocr.Reader(['en'])  # Specify the language(s) you want to use\n",
        "    result = reader.readtext(image_path)\n",
        "\n",
        "    # Combine all detected text into a single string\n",
        "    extracted_text = ' '.join([text[1] for text in result])\n",
        "    return extracted_text\n",
        "\n",
        "# User input for image file\n",
        "image_file_path = input(\"Please enter the path to the image file: \")\n",
        "\n",
        "# Extract symptoms from the image\n",
        "extracted_symptoms = extract_text_from_image(image_file_path)\n",
        "\n",
        "# Predict outputs based on the extracted symptoms\n",
        "predicted_outputs = predict_outputs(extracted_symptoms)\n",
        "\n",
        "# Print the predicted outputs along with the disorder\n",
        "print(f\"Based on extracted symptoms from '{image_file_path}':\")\n",
        "print(f\"Disorder: {predicted_outputs['Disorder']}\")\n",
        "print(f\"Treatment Recommendation: {predicted_outputs['Treatment Recommendation']}\")\n",
        "print(f\"Precautions: {predicted_outputs['Precautions']}\")\n",
        "print(f\"Recommended Food Intake: {predicted_outputs['Food Intake Recommendation']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDZA5ZRCGoTM",
        "outputId": "7e369de7-5fae-4ee2-9698-2e56a3a6eb0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-d4793360118e>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-12-d4793360118e>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-12-d4793360118e>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-12-d4793360118e>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Disorder', 'Symptoms', 'Treatment Recommendation',\n",
            "       'Food Intake Recommendation', 'Precautions', 'Foods to Avoid',\n",
            "       'Duration of Symptoms', 'Lifestyle Recommendations'],\n",
            "      dtype='object')\n",
            "Please enter the path to the image file: /content/DALL·E 2024-10-19 14.51.08 - A visual representation of symptoms including irregular periods, weight gain, and excess hair growth. The image depicts a female figure symbolizing th.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% CompleteBased on extracted symptoms from '/content/DALL·E 2024-10-19 14.51.08 - A visual representation of symptoms including irregular periods, weight gain, and excess hair growth. The image depicts a female figure symbolizing th.jpg':\n",
            "Disorder: PCOS\n",
            "Treatment Recommendation: Lifestyle changes, hormone treatments\n",
            "Precautions: Maintain healthy weight, monitor cycles\n",
            "Recommended Food Intake: Low-carb, high-fiber foods\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn tensorflow transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbkiFjvoJ0xT",
        "outputId": "f5aee7a4-9ad3-4af3-e7f3-294a047316ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras import layers, models  # Importing Keras components\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/gynecological_conditions.csv')  # Update with your dataset path\n",
        "\n",
        "# Define input features and targets\n",
        "X = data['Symptoms']  # Input features (Symptoms)\n",
        "\n",
        "# Targets for prediction\n",
        "targets = ['Disorder', 'Treatment Recommendation', 'Precautions', 'Food Intake Recommendation']\n",
        "target_data = data[targets]\n",
        "\n",
        "# Encoding targets\n",
        "le_targets = {}\n",
        "for target in targets:\n",
        "    le_targets[target] = LabelEncoder()\n",
        "    target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
        "\n",
        "# Split the dataset into training and testing sets for the features\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
        "\n",
        "# Get the corresponding target values for the training and testing sets\n",
        "y_train = target_data.loc[X_train.index]\n",
        "y_test = target_data.loc[X_test.index]\n",
        "\n",
        "# Vectorize the symptoms data for Naive Bayes\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Train and evaluate Naive Bayes Model\n",
        "naive_bayes_model = MultinomialNB()\n",
        "naive_bayes_model.fit(X_train_vectorized, y_train['Disorder'])  # Example for one target\n",
        "y_pred_nb = naive_bayes_model.predict(X_test_vectorized)\n",
        "nb_accuracy = accuracy_score(y_test['Disorder'], y_pred_nb)  # Example for one target\n",
        "print(f\"Naive Bayes Model Accuracy: {nb_accuracy:.4f}\")\n",
        "\n",
        "# Prepare tokenizer and model for LLM (BERT)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(le_targets['Disorder'].classes_))\n",
        "\n",
        "# Function to create TensorFlow datasets\n",
        "def create_tf_dataset(X, y):\n",
        "    encodings = tokenizer(list(X), truncation=True, padding=True, max_length=128)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(encodings), y)).shuffle(1000).batch(16)\n",
        "    return dataset\n",
        "\n",
        "# Create TensorFlow datasets for LLM\n",
        "train_dataset = create_tf_dataset(X_train, y_train['Disorder'])\n",
        "test_dataset = create_tf_dataset(X_test, y_test['Disorder'])\n",
        "\n",
        "# Set up optimizer and loss function using TensorFlow's Adam\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)  # Use TensorFlow's Adam optimizer\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Training Loop for BERT-based model\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    for step, (batch_x, batch_y) in tqdm(enumerate(train_dataset)):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(batch_x, training=True).logits\n",
        "            loss = loss_fn(batch_y, logits)\n",
        "\n",
        "        # Compute gradients and update model\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "# Evaluate the LLM model\n",
        "y_pred_llm = []\n",
        "for batch_x, _ in test_dataset:\n",
        "    logits = model(batch_x, training=False).logits\n",
        "    y_pred_llm.extend(np.argmax(logits, axis=1))\n",
        "\n",
        "llm_accuracy = accuracy_score(y_test['Disorder'], y_pred_llm)\n",
        "print(f\"LLM Model (BERT) Accuracy: {llm_accuracy:.4f}\")\n",
        "\n",
        "# Deep Learning Model: Feedforward Neural Network\n",
        "# Convert text data to TF-IDF features\n",
        "X_train_dl = X_train_vectorized.toarray()  # Convert sparse matrix to dense\n",
        "X_test_dl = X_test_vectorized.toarray()\n",
        "\n",
        "# Build a Feedforward Neural Network\n",
        "dl_model = models.Sequential([\n",
        "    layers.Input(shape=(X_train_dl.shape[1],)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(len(le_targets['Disorder'].classes_), activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "dl_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "dl_model.fit(X_train_dl, y_train['Disorder'], epochs=3, batch_size=16, validation_split=0.1)\n",
        "\n",
        "# Evaluate the deep learning model\n",
        "y_pred_dl = np.argmax(dl_model.predict(X_test_dl), axis=1)\n",
        "dl_accuracy = accuracy_score(y_test['Disorder'], y_pred_dl)\n",
        "print(f\"Deep Learning Model (Feedforward NN) Accuracy: {dl_accuracy:.4f}\")\n",
        "\n",
        "# Function to print accuracies for comparison\n",
        "def print_accuracies():\n",
        "    print(\"Model Accuracies:\")\n",
        "    print(f\"Naive Bayes Accuracy: {nb_accuracy:.4f}\")\n",
        "    print(f\"LLM (BERT) Accuracy: {llm_accuracy:.4f}\")\n",
        "    print(f\"Deep Learning Model Accuracy: {dl_accuracy:.4f}\")\n",
        "\n",
        "# Call the function to display accuracies\n",
        "print_accuracies()\n",
        "\n",
        "# Save the label encoders for future predictions\n",
        "for target in targets:\n",
        "    with open(f'le_{target}.pkl', 'wb') as file:\n",
        "        pickle.dump(le_targets[target], file)\n",
        "\n",
        "# Save the vectorizer for future use\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
        "    pickle.dump(vectorizer, file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlwPP67m4HIG",
        "outputId": "7fe74593-c939-4913-8db7-ace62c87f1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-e888b2ef582d>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-18-e888b2ef582d>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-18-e888b2ef582d>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-18-e888b2ef582d>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Model Accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "360it [08:42,  1.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "360it [08:30,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "360it [08:26,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Model (BERT) Accuracy: 0.0458\n",
            "Epoch 1/3\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8009 - loss: 1.7955 - val_accuracy: 1.0000 - val_loss: 0.0173\n",
            "Epoch 2/3\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
            "Epoch 3/3\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Deep Learning Model (Feedforward NN) Accuracy: 1.0000\n",
            "Model Accuracies:\n",
            "Naive Bayes Accuracy: 1.0000\n",
            "LLM (BERT) Accuracy: 0.0458\n",
            "Deep Learning Model Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pickle\n",
        "import fitz  # PyMuPDF for PDF text extraction\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/gynecological_conditions.csv')\n",
        "\n",
        "# View dataset columns to understand the structure\n",
        "print(data.columns)\n",
        "\n",
        "# Define input features and targets\n",
        "X = data['Symptoms']  # Input features (Symptoms)\n",
        "\n",
        "# Targets for prediction (added more target columns)\n",
        "targets = [\n",
        "    'Disorder',\n",
        "    'Treatment Recommendation',\n",
        "    'Precautions',\n",
        "    'Food Intake Recommendation',\n",
        "    'Foods to Avoid',\n",
        "    'Duration of Symptoms',\n",
        "    'Lifestyle Recommendations'\n",
        "]\n",
        "\n",
        "# Ensure all target columns exist in the dataset\n",
        "target_data = data[targets]\n",
        "\n",
        "# Encoding targets\n",
        "le_targets = {}\n",
        "for target in targets:\n",
        "    le_targets[target] = LabelEncoder()\n",
        "    target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
        "\n",
        "# Split the dataset into training and testing sets for the features\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
        "\n",
        "# Get the corresponding target values for the training and testing sets\n",
        "y_train = target_data.loc[X_train.index]\n",
        "y_test = target_data.loc[X_test.index]\n",
        "\n",
        "# Vectorize the symptoms data\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Train separate Naive Bayes models for each target\n",
        "models = {}\n",
        "for target in targets:\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train_vectorized, y_train[target])  # Using y_train[target] to match the length of X_train_vectorized\n",
        "    models[target] = model\n",
        "\n",
        "# Save the trained models and vectorizer to files\n",
        "with open('naive_bayes_treatment_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(models, model_file)\n",
        "\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
        "    pickle.dump(vectorizer, vectorizer_file)\n",
        "\n",
        "# Function to predict disorder, treatment, precautions, and food intake based on symptoms input\n",
        "def predict_outputs(symptoms):\n",
        "    # Vectorize the input symptoms\n",
        "    input_vectorized = vectorizer.transform([symptoms])\n",
        "\n",
        "    predictions = {}\n",
        "    for target in targets:\n",
        "        predicted_encoded = models[target].predict(input_vectorized)\n",
        "        predictions[target] = le_targets[target].inverse_transform(predicted_encoded)[0]\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as pdf_document:\n",
        "        for page in pdf_document:\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# User input for PDF file\n",
        "pdf_file_path = input(\"Please enter the path to the PDF file: \")\n",
        "\n",
        "# Extract symptoms from the PDF\n",
        "extracted_symptoms = extract_text_from_pdf(pdf_file_path)\n",
        "\n",
        "# Predict outputs based on the extracted symptoms\n",
        "predicted_outputs = predict_outputs(extracted_symptoms)\n",
        "\n",
        "# Print the predicted outputs along with the disorder in the specified format\n",
        "print(f\"Based on extracted symptoms from '{pdf_file_path}':\")\n",
        "print(f\"Disorder: {predicted_outputs['Disorder']}\")\n",
        "print(f\"Treatment Recommendation: {predicted_outputs['Treatment Recommendation']}\")\n",
        "print(f\"Precautions: {predicted_outputs['Precautions']}\")\n",
        "print(f\"Recommended Food Intake: {predicted_outputs['Food Intake Recommendation']}\")\n",
        "print(f\"Foods to Avoid: {predicted_outputs['Foods to Avoid']}\")\n",
        "print(f\"Duration of Symptoms: {predicted_outputs['Duration of Symptoms']}\")\n",
        "print(f\"Lifestyle Recommendations: {predicted_outputs['Lifestyle Recommendations']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPSrBhSG-C5j",
        "outputId": "e9441f35-a1cf-4d30-857d-571a2621d9ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-84b1820d9729>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-4-84b1820d9729>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-4-84b1820d9729>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-4-84b1820d9729>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-4-84b1820d9729>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-4-84b1820d9729>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n",
            "<ipython-input-4-84b1820d9729>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  target_data[target] = le_targets[target].fit_transform(target_data[target])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Disorder', 'Symptoms', 'Treatment Recommendation',\n",
            "       'Food Intake Recommendation', 'Precautions', 'Foods to Avoid',\n",
            "       'Duration of Symptoms', 'Lifestyle Recommendations'],\n",
            "      dtype='object')\n",
            "Please enter the path to the PDF file: /content/PCOS_Medical_Report.pdf\n",
            "Based on extracted symptoms from '/content/PCOS_Medical_Report.pdf':\n",
            "Disorder: PCOS\n",
            "Treatment Recommendation: Medications, surgery\n",
            "Precautions: Maintain healthy weight, monitor cycles\n",
            "Recommended Food Intake: Iron-rich foods\n",
            "Foods to Avoid: Processed sugars\n",
            "Duration of Symptoms: Varies\n",
            "Lifestyle Recommendations: Regular exercise\n"
          ]
        }
      ]
    }
  ]
}